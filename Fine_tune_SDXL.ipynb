{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SDXL Fine-tuning on Replicate\n",
        "\n",
        "Last week, the team at Stability AI open-sourced [SDXL](https://replicate.com/blog/run-sdxl-with-an-api), the newest and most powerful version of Stable Diffusion yet. Replicate was ready from day one with a hosted version of SDXL that you can [run from the web](https://replicate.com/stability-ai/sdxl) or using our [cloud API](https://replicate.com/blog/run-sdxl-with-an-api).\n",
        "\n",
        "Today, we're following up to announce fine-tuning support for SDXL 1.0. In this blog post, we'll show you how to train SDXL on your own images with one line of code and publish the fine-tuned result as your own hosted public or private model."
      ],
      "metadata": {
        "id": "51L4ynq8qPLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate\n",
        "import os\n",
        "import replicate\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "gLWKQvpeqAHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate by setting your token in an environment variable:"
      ],
      "metadata": {
        "id": "iVf3RWPKqKeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get your token from https://replicate.com/account\n",
        "from getpass import getpass\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "id": "NuZ8DpPcqJ0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare your training images\n",
        "\n",
        "The training API expects a zip file containing your training images. A handful of images (5-6) is enough to fine-tune SDXL on a single person, but you might need more if your training subject is more complex or the images are very different. Keep the following guidelines in mind when preparing your images:\n",
        "\n",
        "- Images can be of yourself, your pet, your favorite stuffed animal, or any unique object. For best results, your images should contain only the subject itself, with a minimum of background noise or other objects.\n",
        "- Images can be in JPEG or PNG format.\n",
        "- Dimensions and size don't matter.\n",
        "- Filenames don't matter.\n",
        "- Do not use images of other people without their consent.\n",
        "\n",
        "Put your images in a folder and zip it up. The directory structure of the zip file doesn't matter:\n",
        "\n",
        "```console\n",
        "zip -r data.zip data\n",
        "```\n",
        "\n",
        "Upload this file somewhere on the internet that is publicly accessible, like an S3 bucket or a GitHub Pages site."
      ],
      "metadata": {
        "id": "mNepKK_OquqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Create a model\n",
        "\n",
        "You also need to create a Replicate model that will be the destination for the trained SDXL version. Go to [replicate.com/create](https://replicate.com/create) to create the model. In the example below we call it `my-name/my-model`.\n",
        "\n",
        "You can make your model public or private. If your model is private, only you will be able to run it. If your model is public, anyone will be able to run it, but only you will be able to update it."
      ],
      "metadata": {
        "id": "A7MAt8gZq4h1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start the training"
      ],
      "metadata": {
        "id": "jr8j63kFqijO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "destination_repo = \"\" # @param {type:\"string\"}\n",
        "images_for_training = \"\" # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "rKFfFr1QtdoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import replicate\n",
        "\n",
        "training = replicate.trainings.create(\n",
        "    version=\"stability-ai/sdxl:7ca7f0d3a51cd993449541539270971d38a24d9a0d42f073caf25190d41346d7\",\n",
        "    input={\n",
        "        \"input_images\": images_for_training,\n",
        "    },\n",
        "    destination=destination_repo\n",
        ")"
      ],
      "metadata": {
        "id": "0AefVmqxLIjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Monitor training progress\n",
        "\n",
        "To follow the progress of the training job, visit [replicate.com/trainings](https://replicate.com/trainings) or inspect the training programmatically:"
      ],
      "metadata": {
        "id": "HGiaTo2frZ8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training.reload()\n",
        "print(training.status)\n",
        "if training.status == 'processing':\n",
        "  print(\"\\n\".join(training.logs.split(\"\\n\")[-10:]))"
      ],
      "metadata": {
        "id": "YkRQwY-AtNu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the model\n",
        "\n",
        "When the model has finished training you can run it using the GUI on replicate.com/my-name/my-model, or via the API:\n"
      ],
      "metadata": {
        "id": "5kk3zlqkrl8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = replicate.run(\n",
        "    destination_repo,\n",
        "    input={\"prompt\": \"a photo of TOK riding a rainbow unicorn\"},\n",
        ")"
      ],
      "metadata": {
        "id": "D5RVsCNPro1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained concept is named `TOK` by default, but you can change that by setting `token_string` and `caption_prefix` inputs during the training process."
      ],
      "metadata": {
        "id": "grJ6P-xFrs9K"
      }
    }
  ]
}